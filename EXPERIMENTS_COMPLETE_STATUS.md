# Complete Experiments Status
## All Experiments Analyzed - Ready for Next Run

**Date:** January 21, 2026, 10:00 AM  
**Git Status:** Clean (2 commits ahead of origin)  
**Overall:** âš ï¸ **Code ready, Paper needs 3 revisions**

---

## ðŸ“Š ALL EXPERIMENTS INVENTORY

### **Experiment 1: ACE Main** (Core Contribution)

**File:** `ace_experiments.py`  
**Type:** DPO-based learning policy  
**Paper Section:** 3.4.1, Methods, Discussion  
**Status:** âœ… **Updated with Jan 21 fixes** - Ready to test

**What it does:**
- LLM policy generates interventions
- DPO training on preference pairs
- Learns experimental design strategy through self-play

**Issues Found (Jan 20 run):**
- âŒ 99% zero rewards â†’ âœ… Fixed (novelty bonus)
- âŒ Zero gradients â†’ âœ… Fixed (emergency retraining)
- âŒ Diversity penalty â†’ âœ… Fixed (adaptive threshold)
- âŒ Too slow â†’ âœ… Fixed (dynamic candidates)

**Next Action:** `./pipeline_test.sh` then `sbatch jobs/run_ace_main.sh`

---

### **Experiment 2: Baselines** (Comparison)

**File:** `baselines.py`  
**Type:** 4 baseline policies for comparison  
**Paper Section:** 3.8 (Baselines), Discussion  
**Status:** âœ… **Complete + PPO bug fixed**

**What it includes:**
1. Random - uniform sampling
2. Round-Robin - systematic cycling
3. Max-Variance - greedy uncertainty sampling
4. PPO - value-based RL

**Results (from logs copy):**
- Round-Robin: 1.9859 (BEST)
- Random: 2.1709
- Max-Variance: 2.0924
- PPO: 2.1835 (had bug, now fixed)

**Next Action:** Rerun PPO with fix: `python baselines.py --baseline ppo --episodes 100`

---

### **Experiment 3: Complex 15-Node SCM** (Scaling Validation)

**File:** `experiments/complex_scm.py`  
**Type:** Heuristic policy comparison (NOT ACE/DPO)  
**Paper Section:** 3.4.2 (Complex SCM)  
**Status:** ðŸ”„ **Running** (greedy_collider in progress)

**What it tests:**
- 3 policies: random, smart_random, greedy_collider
- 15 nodes, 5 colliders (vs 5 nodes, 1 collider)
- Shows strategic intervention matters at scale

**Important:** This does NOT use ACE/DPO - it uses simple heuristic policies

**Results:**
- âœ… Random: Complete
- âœ… Smart_random: Complete
- ðŸ”„ Greedy_collider: Running

**Paper Alignment:**
- âš ï¸ Line 609 says "ACE becomes more pronounced" but it's testing heuristics
- **Fix:** Change to "strategic intervention becomes more pronounced"

**Next Action:** Wait for completion, then verify greedy > smart > random

---

### **Experiment 4: Duffing Oscillators** (Physics Validation)

**File:** `experiments/duffing_oscillators.py`  
**Type:** Random intervention policy (NOT ACE)  
**Paper Section:** 3.6 (Physics)  
**Status:** âœ… **Complete** (<1 min runtime)

**What it does:**
- Coupled oscillators with ODE simulation
- Random intervention policy
- Structure discovery (chain topology)
- Tests framework on continuous dynamics

**Important:** Uses RANDOM policy, not ACE/DPO

**Results (from logs copy):**
- Runtime: <1 minute
- 100 episodes completed
- Structure learning successful

**Paper Alignment:**
- ðŸ”´ **Line 661 says "ACE discovers clamping strategy"** - INCORRECT
- Reality: Random policy, no discovery/learning
- **Fix:** Remove "ACE discovers", describe actual approach

**Next Action:** 
1. Run `python clamping_detector.py` to verify if clamping emerged
2. Revise paper line 661 based on findings

---

### **Experiment 5: Phillips Curve** (Economics Validation)

**File:** `experiments/phillips_curve.py`  
**Type:** Hardcoded regime selection (NOT ACE)  
**Paper Section:** 3.7 (Economics)  
**Status:** âœ… **Complete** (~30 sec runtime)

**What it does:**
- Real FRED data (unemployment, fed funds, CPI)
- Hardcoded regime selection strategy
- Retrospective learning across historical periods

**Important:** Regime selection is HARDCODED, not learned

**Results (from logs copy):**
- 552 records from FRED
- 6 regimes processed
- 100 episodes completed

**Paper Alignment:**
- ðŸ”´ **Line 714 says "ACE learns to query regimes"** - INCORRECT
- Reality: Hardcoded regime order, no learning
- **Fix:** Change to "systematic querying of"

**Next Action:**
1. Run `python regime_analyzer.py` to document regime distribution
2. Revise paper line 714 to match reality

---

## ðŸš¨ CRITICAL ALIGNMENT ISSUES

### **Summary:**

| Experiment | Paper Claim | Reality | Severity |
|------------|-------------|---------|----------|
| ACE Main | Uses DPO | âœ… Uses DPO | âœ… ALIGNED |
| Baselines | 4 methods | âœ… 4 methods | âœ… ALIGNED |
| Complex SCM | "ACE" advantage | âš ï¸ Heuristics | âš ï¸ CLARIFY |
| **Duffing** | **"ACE discovers"** | **âŒ Random policy** | **ðŸ”´ CRITICAL** |
| **Phillips** | **"ACE learns"** | **âŒ Hardcoded** | **ðŸ”´ CRITICAL** |

---

## ðŸŽ¯ DO EXPERIMENTS NEED CHANGES?

### **Code Changes Needed:** âœ… **NO**

All experiments work correctly for their intended purposes:
- âœ… Complex SCM tests strategic vs random policies
- âœ… Duffing validates physics domain
- âœ… Phillips validates economics domain
- âœ… All produce useful results

**No bugs, no failures, no fixes needed in experiments/ directory.**

---

### **Paper Changes Needed:** âš ï¸ **YES - 3 Claims**

Must revise before submission:

1. **Line 661 (Duffing):** Remove "ACE discovers clamping"
2. **Line 714 (Phillips):** Remove "ACE learns regimes"
3. **Line 609 (Complex):** Clarify "strategic policies" not "ACE"

**Timeline:** 1 hour to revise + verify  
**Impact:** Minimal - experiments still valuable, just accurately described

---

## ðŸ“‹ COMPLETE EXPERIMENTAL PIPELINE STATUS

| Component | Purpose | Status | Code OK | Paper OK | Action |
|-----------|---------|--------|---------|----------|--------|
| **ACE Main** | Core learning | â³ Need run | âœ… Fixed | âœ… OK | Test & run |
| **Baselines** | Comparison | âœ… Complete | âœ… Fixed | âœ… OK | Rerun PPO |
| **Complex SCM** | Scaling | ðŸ”„ Running | âœ… OK | âš ï¸ Clarify | Wait & revise |
| **Duffing** | Physics | âœ… Complete | âœ… OK | ðŸ”´ Fix | Verify & revise |
| **Phillips** | Economics | âœ… Complete | âœ… OK | ðŸ”´ Fix | Verify & revise |

---

## ðŸŽ¯ WHAT NEEDS TO ALIGN

### **Experiments Need:**
- âœ… No code changes
- âœ… No bug fixes
- âœ… No performance improvements
- âœ… All work as designed

### **Paper Needs:**
- âš ï¸ Accurate description of Duffing (line 661)
- âš ï¸ Accurate description of Phillips (line 714)
- âš ï¸ Clarification about Complex SCM (line 609)

### **Verification Needs:**
- â³ Run `clamping_detector.py` on Duffing results
- â³ Run `regime_analyzer.py` on Phillips results
- â³ Confirm Complex SCM shows greedy > random

---

## ðŸš€ COMPLETE NEXT RUN PROCEDURE

### **Phase 1: Test Pipeline** (30 minutes)
```bash
./pipeline_test.sh
```
**Tests:** ACE fixes, PPO fix, verification tools  
**Expected:** All tests pass

---

### **Phase 2: Launch All Experiments** (6-10 hours)
```bash
# ACE Main (most important)
sbatch jobs/run_ace_main.sh  # 4-6 hours

# PPO Rerun (parallel)
nohup python baselines.py --baseline ppo --episodes 100 \
    --output results/ppo_fixed_$(date +%Y%m%d_%H%M%S) > ppo.log 2>&1 &

# Complex SCM (already running)
# Just wait for completion
```

**Note:** Duffing and Phillips already complete, no rerun needed

---

### **Phase 3: Verify ALL Experiments** (2 hours)
```bash
# 1. Verify behavioral claims
python clamping_detector.py   # Duffing: Check if clamping emerged
python regime_analyzer.py      # Phillips: Document regime distribution
./verify_claims.sh             # All experiments

# 2. Extract metrics
./extract_baselines.sh         # Baseline comparison
./extract_ace.sh               # ACE results (after run)
python compare_methods.py      # Table 1 generation

# 3. Verify complex SCM results
grep "FINAL RESULTS" results/paper_*/complex_scm/*/experiment.log
# Check: greedy_collider < smart_random < random
```

---

### **Phase 4: Update Documentation** (1 hour)
```bash
# 1. Document all findings
code results/RESULTS_LOG.md
# Add entries for:
# - ACE main run
# - PPO rerun
# - Complex SCM completion
# - Verification results

# 2. Update summary dashboard
# Change all â³ to âœ… or âš ï¸ based on findings
```

---

### **Phase 5: Fill Paper & Revise** (3 hours)
```bash
# 1. Fill all tables with real numbers
code paper/paper.tex

# Tables to fill:
# - Line 428-437: Table 1 (Synthetic 5-node)
# - Line 600-608: Table 2 (Complex SCM)
# - Line 652-660: Table 3 (Duffing)
# - Line 705-713: Table 4 (Phillips)
# - Line 718-727: Table 5 (Summary)

# 2. Replace all [PLACEHOLDER] inline values

# 3. Revise 3 claims based on alignment check:
# - Line 661: Duffing clamping
# - Line 714: Phillips regimes
# - Line 609: Complex SCM
```

---

## âœ… FINAL CHECKLIST

### **Code/Experiments:**
- [x] ACE main fixes implemented
- [x] PPO bug fixed
- [x] Verification tools created
- [x] Extraction scripts ready
- [x] All experiments working correctly
- [x] Git committed and clean

### **Need to Run:**
- [ ] `./pipeline_test.sh` (30 min)
- [ ] `sbatch jobs/run_ace_main.sh` (4-6 hours)
- [ ] Rerun PPO (2 hours)
- [ ] Wait for complex_scm completion

### **Need to Verify:**
- [ ] Clamping in Duffing (run detector)
- [ ] Regimes in Phillips (run analyzer)
- [ ] Strategic advantage in Complex SCM (check results)

### **Need to Update:**
- [ ] Fill 5 paper tables
- [ ] Replace all [PLACEHOLDER]
- [ ] Revise 3 paper claims (lines 609, 661, 714)
- [ ] Update results/RESULTS_LOG.md

### **Can Submit When:**
- [ ] All experiments complete
- [ ] All tables filled
- [ ] All claims verified or revised
- [ ] Final review complete

---

## ðŸŽ¯ ALIGNMENT SUMMARY

### **Q: Do experiments need further work to align?**

**A: NO code changes needed, YES paper revisions needed.**

**Code:** âœ… All experiments work correctly  
**Paper:** âš ï¸ 3 claims over-state what they do

**Solution:** Verify behaviors with tools, revise paper claims (1-2 hours work)

---

### **What's Aligned:**
- âœ… ACE main (core contribution)
- âœ… Baselines (all 4 methods)
- âœ… Experiments produce useful validation data

### **What Needs Alignment:**
- âš ï¸ Paper descriptions of Duffing, Phillips, Complex SCM
- âš ï¸ 3 specific claims that say "ACE" when it's actually heuristics

### **Impact:**
- Low - experiments still validate multi-domain applicability
- Just needs honest description of what each does

---

## ðŸš€ READY FOR NEXT RUN

**Git Status:** âœ… Clean, 2 commits ahead  
**Code Status:** âœ… All experiments ready  
**Paper Status:** âš ï¸ Needs 3 minor revisions  

**Immediate Action:**
```bash
./pipeline_test.sh
```

**After Test:**
```bash
sbatch jobs/run_ace_main.sh
```

**After Runs:**
```bash
# Verify
python clamping_detector.py
python regime_analyzer.py

# Extract
./extract_ace.sh
python compare_methods.py

# Document
code results/RESULTS_LOG.md

# Revise paper
code paper/paper.tex
# Lines 609, 661, 714
```

---

## ðŸ“– Key Documents

**For current status:** `START_HERE.md`  
**For all experiments:** `EXPERIMENTS_ALIGNMENT_CHECK.md` (this analysis)  
**For paper revisions:** `results/PAPER_REVISIONS_NEEDED.md`  
**For tracking results:** `results/RESULTS_LOG.md`  

---

**Summary:** All 5 experiments analyzed. Code is ready. Paper needs minor revisions. Proceed with testing! ðŸš€
